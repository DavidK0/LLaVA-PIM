# LLaVA-PIM
In this repo I use the vision-language model LLaVA to extract product information from shelf images. The goal is to start with a cropped image of some product sitting on a shelf, and extract as much product information from that image as possible (eg. brand, size, nutritional information, etc.).

